from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import time
import smtplib
import os
import gradio as gr
import psycopg2
import pandas as pd
import plotly.graph_objects as go
from openai import OpenAI
from datetime import datetime, timedelta
from datetime import date
import requests
from PIL import Image
from io import BytesIO

from langchain.agents import initialize_agent, Tool
from langchain_openai import ChatOpenAI
from langchain_community.utilities import WikipediaAPIWrapper
from langchain_community.tools import WikipediaQueryRun
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

# ---------- Global Variable ----------
last_generated_report = ""  # Store the latest generated report for email sending
# ---------- Config ----------
DB_CONFIG = {
    "host": os.environ.get("DB_HOST"),
    "port": os.environ.get("DB_PORT"),
    "dbname": os.environ.get("DB_NAME"),
    "user": os.environ.get("DB_USER"),
    "password": os.environ.get("DB_PASSWORD")}

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

API_BASE = "http://fastapi:8000"


# langchain
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    streaming=True, 
    callbacks=[StreamingStdOutCallbackHandler()],
    temperature=0.7)

# ---------- Email Sending ----------
def send_email_report(to_email, subject, report_content):
    sender_email = os.getenv("SENDER_EMAIL")
    sender_password = os.getenv("SENDER_PASSWORD")
    try:
        msg = MIMEMultipart()
        msg['From'] = sender_email
        msg['To'] = to_email
        msg['Subject'] = subject
        msg.attach(MIMEText(report_content, 'plain'))

        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(sender_email, sender_password)
        server.send_message(msg)
        server.quit()

        return f"Report sent to {to_email}"
    except Exception as e:
        return f"Failed to send email: {e}"

# ---------- Data Fetching ----------

def fetch_economic_index_summary(index_name: str = None, days: int = 180):
    try:
        params = {"days": days}
        if index_name:
            params["index_name"] = index_name

        response = requests.get(f"{API_BASE}/economic_index", params=params)
        response.raise_for_status()
        data = response.json()

        if not data:
            return pd.DataFrame(), "No data found"

        df = pd.DataFrame(data)

        summary = "\n".join([f"{row['date']} | {row['index_name']} | {row['value']}" for row in data])
        return df, summary

    except Exception as e:
        print("API ERROR:", e)
        return pd.DataFrame(), f"API error: {e}"
    
def fetch_market_price_summary(market):
    try:
        res = requests.get(
            f"{API_BASE}/market_price", 
            params={"market": market}
        )
        res.raise_for_status()
        data = res.json()

        if not data:
            return pd.DataFrame(), "No data"

        df = pd.DataFrame(data)
        df["date"] = pd.to_datetime(df["date"])

        df = df[["date", "market", "price"]]

        summary = "\n".join([
            f"{row['date'].date()} | {row['market']} | Price: {row['price']}"
            for _, row in df.iterrows()
        ])

        return df, summary

    except Exception as e:
        print("API error:", e)
        return pd.DataFrame(), f"API error: {e}"
        return pd.DataFrame(), f"API error: {e}"

def fetch_overall_sentiment_summary():
    conn, cursor = None, None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT 
            topic_date, 
            pos_count,
            neg_count
            FROM dbt_us_stock_data_production.reddit_comment_us_market_daily
        """)
        rows = cursor.fetchall()
        return pd.DataFrame(rows, columns=["published_at", "total_pc", "total_nc"])
    except Exception as e:
        return pd.DataFrame([{"error": str(e)}])
    finally:
        if cursor: cursor.close()
        if conn: conn.close()

def fetch_sentiment_data():
    try:
        res = requests.get(f"{API_BASE}/sentiment/reddit_summary/compare")
        res.raise_for_status()
        data = res.json()

        df = pd.DataFrame([
            {
                "label": "This Week",
                "date": data["recent_7d"]["date"],
                "total": data["recent_7d"]["total"],
                "positive": data["recent_7d"]["positive"],
                "negative": data["recent_7d"]["negative"]
            },
            {
                "label": "Last Week",
                "date": data["prev_7d"]["date"],
                "total": data["prev_7d"]["total"],
                "positive": data["prev_7d"]["positive"],
                "negative": data["prev_7d"]["negative"]
            }
        ])
        return df, None
    except Exception as e:
        return pd.DataFrame(), f"âŒ Failed to fetch: {e}"
    
def fetch_sentiment_topic_summary():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        cursor.execute("""
            SELECT 
                topic_date,
                topic_summary,
                keywords,
                comments_count,
                pos_count,
                neg_count,
                source
            FROM dbt_us_stock_data_production."top_5_Topic_with_sentiment"
            WHERE topic_date = (
                SELECT MAX(topic_date) FROM dbt_us_stock_data_production."top_5_Topic_with_sentiment"
            )
            ORDER BY comments_count DESC, topic_date DESC
            LIMIT 10;
        """)

        rows = cursor.fetchall()
        if not rows:
            return pd.DataFrame(), "No data found"
        df = pd.DataFrame(rows, columns=["date", "title", "keywords", "comment_count", "positive", "negative","source"])
        summary = "\n".join([f"{r[0]} | {r[1]} | {r[2]} | {r[3]} | {r[4]} | {r[5]} | {r[6]}" for r in rows])
        return df, summary
    
    except Exception as e:
        return pd.DataFrame(), f"Database error: {e}"
    finally:
        if cursor: cursor.close()
        if conn: conn.close()

def fetch_top10_symbols_this_week():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        query = """
            WITH this_week AS (
                SELECT 
                    symbol,
                    SUM(comments_count) AS total_comments,
                    SUM(pos_count) AS total_pos,
                    SUM(neg_count) AS total_neg
                FROM dbt_us_stock_data_production.sp500_sentiment_reddit
                WHERE snapshot_date = (SELECT MAX(snapshot_date) FROM dbt_us_stock_data_production.sp500_sentiment_reddit)
                  AND symbol IS NOT NULL
                GROUP BY symbol
            )
            SELECT 
                symbol,
                total_comments,
                total_pos,
                total_neg
            FROM this_week
            ORDER BY total_comments DESC
            LIMIT 10
        """
        cursor.execute(query)
        rows = cursor.fetchall()

        if not rows:
            return pd.DataFrame(), "No data found"

        df = pd.DataFrame(rows, columns=["ğŸ”¥ Symbol", "ğŸ’¬ Comments", "ğŸ‘ Positive", "ğŸ‘ Negative"])
        summary = "\n".join([f"{r[0]} | {r[1]} | {r[2]} | {r[3]}" for r in rows])
        return df,summary

    except Exception as e:
        return pd.DataFrame(), f"Database error: {e}"

    finally:
        if cursor: cursor.close()
        if conn: conn.close()

def fetch_top5_sectors_this_week():
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        query = """
            WITH this_week AS (
                SELECT 
                    sector,
                    SUM(comments_count) AS total_comments,
                    SUM(pos_count) AS total_pos,
                    SUM(neg_count) AS total_neg
                FROM dbt_us_stock_data_production.sp500_sentiment_reddit
                WHERE snapshot_date = (SELECT MAX(snapshot_date) FROM dbt_us_stock_data_production.sp500_sentiment_reddit)
                GROUP BY sector
            )
            SELECT 
                sector,
                total_comments,
                total_pos,
                total_neg
            FROM this_week
            ORDER BY total_comments DESC
            LIMIT 5
        """
        cursor.execute(query)
        rows = cursor.fetchall()

        if not rows:
            return pd.DataFrame(), "No this week data"

        df = pd.DataFrame(rows, columns=["sector", "total_comments", "total_pos", "total_neg"])

        summary = "\n".join([f"{r[0]} | {r[1]} | {r[2]} | {r[3]}" for r in rows])
        return df, summary

    except Exception as e:
        return pd.DataFrame(), f"Database error: {e}"

    finally:
        if cursor: cursor.close()
        if conn: conn.close()

def fetch_market_price_last_7_days():
    conn, cursor = None, None
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()

        query = """
            SELECT 
                market,
                snapshot_time,
                price,
                ma_3_days,
                ma_5_days,
                ma_7_days
            FROM dbt_us_stock_data_production.market_price
            WHERE snapshot_time >= (SELECT MAX(snapshot_time) FROM dbt_us_stock_data_production.market_price) - INTERVAL '7 days'
            ORDER BY snapshot_time DESC;
        """

        cursor.execute(query)
        rows = cursor.fetchall()

        if not rows:
            return pd.DataFrame(), "No data found."

        df = pd.DataFrame(rows, columns=[
            "market", "snapshot_time", "price", "ma_3_days", "ma_5_days", "ma_7_days"
        ])

        # Summary for ai 
        summary = "\n".join([
            f"{row[1]} | {row[0]} | price: {row[2]} | MA3: {row[3]} | MA5: {row[4]} | MA7: {row[5]}"
            for row in rows
        ])

        return df, summary

    except Exception as e:
        return pd.DataFrame(), f"Database error: {e}"

    finally:
        if cursor:
            cursor.close()
        if conn:
            conn.close()

def search_news_for_keywords(keywords, max_articles=3):
    NEWS_API_KEY = os.getenv("NEWS_API_KEY")
    query = " OR ".join(keywords[:5])
    from_date = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d")
    url = f"https://newsapi.org/v2/everything?q={query}&sortBy=publishedAt&from={from_date}&pageSize={max_articles}&apiKey={NEWS_API_KEY}"
    try:
        response = requests.get(url, timeout=10)
        articles = response.json().get("articles", [])
        if not articles:
            return "No news found."
        return "\n\n".join([f"ã€{a['title']}ã€‘\n{a['description']}\nLink: {a['url']}" for a in articles])
    except Exception as e:
        return f"News search error: {e}"

# ----------- Save back to DB---------------

def save_to_db(age, experience, interest, sources, risk,language, email):
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()


        interest_array = "{" + ",".join(interest) + "}"

        upsert_query = """
        INSERT INTO raw_data.user_profiles (age, experience, interest, sources, risk,language, email)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
        ON CONFLICT (email)
        DO UPDATE SET
        age = EXCLUDED.age,
        experience = EXCLUDED.experience,
        interest = EXCLUDED.interest,
        sources = EXCLUDED.sources,
        risk = EXCLUDED.risk,
        language = EXCLUDED.language
        """

        cur.execute(upsert_query, (
            age, experience, interest_array, sources, risk, language, email
        ))

        conn.commit()
        cur.close()
        conn.close()

        
        user_profile = {
            "age": age,
            "experience": experience,
            "interest": interest,
            "sources": sources,
            "risk": risk,
            "language": language,
            "email": email
        }
        return "âœ… Your response has been saved!", user_profile
    except Exception as e:
        return f"âŒ Database error: {e}"

# ---------- plot ---------
def plot_sentiment_line_chart():
    df = fetch_overall_sentiment_summary()
    if df.empty or "error" in df.columns:
        return go.Figure().update_layout(title="âŒ Failed to load data")
    
    df["total_pc"] = pd.to_numeric(df["total_pc"], errors="coerce")
    df["total_nc"] = pd.to_numeric(df["total_nc"], errors="coerce")

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df["published_at"], y=df["total_pc"], mode="lines+markers", name="Positive"))
    fig.add_trace(go.Scatter(x=df["published_at"], y=df["total_nc"], mode="lines+markers", name="Negative"))
    fig.update_layout(title="ğŸ“Š Reddit Daily Market Sentiment Trend ",height=515 ,xaxis_title="Date", yaxis_title="Comment Count")
    return fig

def plot_sentiment_pie(df):
    if df.empty:
        return go.Figure().update_layout(title="No data"), go.Figure()

    def make_pie_row(row):
        neutral = max(row["total"] - row["positive"] - row["negative"], 0)
        labels = ["Positive", "Neutral", "Negative"]
        values = [row["positive"], neutral, row["negative"]]
        title = f"{row['label']} ({row['date']})"
        fig = go.Figure(data=[go.Pie(labels=labels, values=values,hole=0.4)])
        fig.update_layout(title_text=title,height=250,margin=dict(t=10, b=10, l=10, r=10))
        return fig

    this_week_fig = make_pie_row(df.iloc[0])
    last_week_fig = make_pie_row(df.iloc[1])

    return this_week_fig, last_week_fig

def plot_index_chart(df: pd.DataFrame, title: str = ""):
    if df.empty:
        return go.Figure().update_layout(title="Failed to load data")

    df["value"] = pd.to_numeric(df["value"], errors="coerce")

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=df["date"],
        y=df["value"],
        mode="lines+markers",
        name=title or "Index"
    ))
    fig.update_layout(
        title=title,
        xaxis=dict(tickangle=-45, dtick="M1"),
        yaxis_title="Value",
        xaxis_title="Date",
        margin=dict(l=20, r=20, t=30, b=30),
        height=350
    )
    return fig

def plot_price_chart(market):
    df, summary = fetch_market_price_summary(market)
    if df.empty:
        return go.Figure().update_layout(title="Failed to load data")

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=df["date"], y=df["price"],
        mode="lines+markers", name=market
    ))
    fig.update_layout(
        title=f"{market} - Price Trend (30 Days)",
        xaxis_title="Date",
        yaxis_title="Price",
        height=350
    )
    return fig

def get_sentiment_table():
    df, _ = fetch_sentiment_topic_summary()
    last_time = df['date'].max().strftime("%Y-%m-%d %H:%M:%S")
    df1 = df[["source","positive", "negative","title"]]
    
    return df1, last_time 

def plot_sector_chart():
    df, _ = fetch_top5_sectors_this_week()

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=df["sector"],
        y=df["total_comments"],
        name="Total Comments",
        text=df["total_comments"],
        textposition="auto"
    ))

    fig.update_layout(
        title="Top 5 Sectors by Discussions",
        xaxis_title="Sector",
        yaxis_title="Total Comments",
        height=400,
        margin=dict(l=20, r=20, t=50, b=30),
    )

    return fig
# ---------- image ----------

def show_image(filename):
    image_path = os.path.join("/app/assets", filename)
    return Image.open(image_path)

# ---------- stocke recommendation

def g4_recommend_multi(symbols_raw, email):
    # è™•ç†è¼¸å…¥ï¼šåˆ‡é€—è™Ÿã€å»ç©ºæ ¼ã€è½‰å¤§å¯«
    symbols = [s.strip().upper() for s in symbols_raw.split(",") if s.strip()]
    print(f"[INPUT] ä½¿ç”¨è€…è¼¸å…¥è‚¡ç¥¨ï¼š{symbols}")

    if not symbols:
        return "è«‹è‡³å°‘è¼¸å…¥ä¸€å€‹è‚¡ç¥¨ä»£ç¢¼", ""

    url = "http://fastapi:8000/recommend/"
    # çµ„åˆæŸ¥è©¢åƒæ•¸ï¼šsymbols å¤šå€¼ + user_id
    params = [("symbols", s) for s in symbols]
    if email:
        params.append(("user_id", email))  # âœ… å‚³å…¥ email ç•¶ä½œ user_id
    else:
        params.append(("user_id", "anonymous"))

    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        print("[API å›å‚³è³‡æ–™]", data)

        if data.get("status") == "ok":
            recs = data.get("recommendations", [])
            return "", "\n".join(recs) if recs else "æ²’æœ‰æ¨è–¦çµæœ"
        else:
            return "æ¨è–¦å¤±æ•—ï¼ŒAPI å›å‚³é ok ç‹€æ…‹", ""
    except Exception as e:
        return f"éŒ¯èª¤ï¼š{str(e)}", ""

def fetch_industries():
    try:
        resp = requests.get(f"{API_BASE}/stock_data/sector_list")
        return [""] + [i for i in resp.json() if i]
    except Exception:
        return []

def fetch_max_date():
    try:
        resp = requests.get(f"{API_BASE}/stock_data/latest_date")
        return pd.to_datetime(resp.json()).date()
    except Exception:
        return date.today()
    
def query_stock_data(symbol, sector, start_date, end_date):
    try:
        params = []

        if symbol:
            symbol_list = [s.strip() for s in symbol.split(",") if s.strip()]
            for s in symbol_list:
                params.append(("symbol", s))

        if sector:
            params.append(("sector", sector))
        if start_date:
            params.append(("start_date", start_date))
        if end_date:
            params.append(("end_date", end_date))

        
        resp = requests.get(f"{API_BASE}/stock_data", params=params)

        if resp.status_code != 200:
            return pd.DataFrame([{"éŒ¯èª¤": f"HTTP {resp.status_code}", "è¨Šæ¯": resp.text}])

        try:
            data = resp.json()
        except Exception as e:
            return pd.DataFrame([{"éŒ¯èª¤": "JSON decode error", "è¨Šæ¯": str(e)}])

        if not data:
            return pd.DataFrame([{"è¨Šæ¯": "æŸ¥ç„¡è³‡æ–™"}])

        return pd.DataFrame(data)

    except Exception as e:
        return pd.DataFrame([{"éŒ¯èª¤": "æŸ¥è©¢å¤±æ•—", "è¨Šæ¯": str(e)}])
# ---------- Report Generation ----------

def generate_overall_report(
    economic_summary: str,
    market_sentiment_summary: str,
    stock_recommender_summary: str,
    language: str = "English"
):

    try:
        if language.lower() in ["chinese", "zh", "ä¸­æ–‡"]:
            prompt = f"""è«‹æ ¹æ“šä»¥ä¸‹ä¸‰ä»½è³‡æ–™ï¼Œæ’°å¯«ä¸€ä»½å®Œæ•´çš„ç¸½é«”ç¶“æ¿Ÿèˆ‡å¸‚å ´è§€å¯Ÿåˆ†æå ±å‘Šã€‚è«‹ä»¥ç¶“æ¿Ÿå­¸è¦–è§’åˆ‡å…¥ï¼Œèªæ°£å°ˆæ¥­åš´è¬¹ï¼Œé©åº¦ä½¿ç”¨å°ˆæœ‰åè©ä¸¦åœ¨é¦–æ¬¡å‡ºç¾æ™‚æä¾›ç°¡å–®è§£é‡‹ï¼›åŒæ™‚é ˆæ³¨æ„ç”¨è©æ¸…æ™°ï¼Œè®“ä¸€èˆ¬è®€è€…ä¹Ÿèƒ½ç†è§£ã€‚

ğŸ“˜ ç¶“æ¿Ÿæ¦‚æ³å ±å‘Šï¼š
{economic_summary}

ğŸ“Š å¸‚å ´æƒ…ç·’å ±å‘Šï¼š
{market_sentiment_summary}

ğŸ“ˆ å€‹è‚¡æŠ•è³‡å»ºè­°æ‘˜è¦ï¼š
{stock_recommender_summary}

è«‹å°‡å ±å‘Šçµ„ç¹”ç‚ºä»¥ä¸‹çµæ§‹ï¼Œæ¯æ®µæ˜ç¢ºé‡å°å°æ‡‰è³‡æ–™å…§å®¹ï¼š

1. **ç¶“æ¿Ÿè¶¨å‹¢åˆ†æ**ï¼šæ¦‚è¿°ç›®å‰çš„ç¸½é«”ç¶“æ¿Ÿç‹€æ³ï¼ˆå¦‚ GDPã€é€šè†¨ã€åˆ©ç‡ç­‰ï¼‰ï¼Œä¸¦èªªæ˜é€™äº›æŒ‡æ¨™å¯èƒ½å°ä¼æ¥­ç‡Ÿé‹èˆ‡ä¸€èˆ¬æ¶ˆè²»è€…ç”¢ç”Ÿçš„å¯¦è³ªå½±éŸ¿ã€‚

2. **å¸‚å ´æƒ…ç·’è§£è®€**ï¼šå¾å¸‚å ´æƒ…ç·’è³‡æ–™ä¸­è§£ææŠ•è³‡äººç•¶å‰çš„åæ‡‰èˆ‡é¢¨éšªåå¥½ï¼Œä¸¦æŒ‡å‡ºç›®å‰å¸‚å ´ç„¦é»ç”¢æ¥­èˆ‡é—œéµå€‹è‚¡æ˜¯å¦åæ˜ éåº¦æ¨‚è§€æˆ–è¬¹æ…çš„æ°›åœã€‚

3. **å€‹è‚¡å»ºè­°è©•æ**ï¼šç¸½çµ AI æ‰€æå‡ºçš„å€‹è‚¡å»ºè­°å…§å®¹ï¼Œèªªæ˜æ¨è–¦é‚è¼¯æ˜¯å¦åˆç†ï¼Œä¸¦å¾ç”¢æ¥­åˆ†å¸ƒæˆ–é¢¨éšªåˆ†æ•£è§’åº¦è£œå……å°ˆæ¥­è§€é»ã€‚

4. **æ•´é«”çµè«–èˆ‡å»ºè­°**ï¼šç¶œåˆä¸Šè¿°æ®µè½ï¼Œç¸½çµç›®å‰å¯æ¡å–çš„è³‡ç”¢é…ç½®ç­–ç•¥ï¼ŒåŒ…å«å°ä¸åŒé¢¨éšªå±¬æ€§çš„æŠ•è³‡äººæ‡‰æœ‰çš„å»ºè­°ï¼ˆå¦‚ç©©å¥å‹ã€æˆé•·å‹ã€ä¿å®ˆå‹ï¼‰ï¼Œä¸¦æé†’æ‡‰é—œæ³¨çš„æ½›åœ¨è®Šæ•¸ã€‚

å­—æ•¸æ§åˆ¶åœ¨ 600 å­—ä»¥å…§ï¼Œèªæ°£å°ˆæ¥­ã€æ¢ç†æ¸…æ™°ï¼Œé¿å…éåº¦è‰±æ¾€ï¼Œä½†ä¸éœ€éåº¦ç°¡åŒ–å…§å®¹ã€‚
"""
        else:
            prompt = f"""Based on the following three reports, generate a well-structured, professional market and economic outlook. The tone should be analytical and objective, incorporating appropriate financial terminology (with brief explanations when needed), but still understandable to a non-technical reader.

ğŸ“˜ Economic Summary:
{economic_summary}

ğŸ“Š Market Sentiment Report:
{market_sentiment_summary}

ğŸ“ˆ Stock Recommendation Summary:
{stock_recommender_summary}

Your report (max ~600 words) should include the following structure:

1. **Macroeconomic Overview**: Summarize the current macroeconomic conditions (e.g., GDP trends, inflation, interest rates) and explain how they may affect businesses and consumer behavior.

2. **Market Sentiment Analysis**: Interpret investor behavior and risk appetite based on sentiment data, highlighting sectors or stocks receiving unusually high attention and whether sentiment appears justified.

3. **Equity Recommendation Review**: Review the AI-generated stock recommendations, explaining the rationale behind them and offering professional insight into sector diversification and potential portfolio impact.

4. **Conclusion and Strategic Suggestions**: Tie together the above sections into a cohesive summary. Offer tailored asset allocation guidance for different risk profiles (e.g., conservative, balanced, aggressive), and note any key risks or indicators to monitor.

Maintain a clear and coherent narrative, with logical transitions between sections. The report should feel like a brief yet insightful investment commentary."""

        res = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a senior investment strategist who synthesizes multi-source information."},
                {"role": "user", "content": prompt}
            ]
        )

        report = res.choices[0].message.content
        return report

    except Exception as e:
        return f"Error generating overall report: {e}"


def get_economic_report(language='English'):
    

    try:
        res = requests.post("http://fastapi:8000/report/generate/", json={"language": language})
        res.raise_for_status()

        return res.text, res.text
    except Exception as e:
        print("Error fetching report:", e)
        return "Failed to fetch report."

def get_market_sentiment_report(language='English'):
    
    try:
        df = fetch_overall_sentiment_summary()
        _, sentiment_summary = fetch_sentiment_topic_summary()
        _, top_sector_summary = fetch_top5_sectors_this_week()
        _, symbol_summary = fetch_top10_symbols_this_week()

        # å»ºç«‹ promptï¼ˆä¸­è‹±åˆ‡æ›ï¼‰
        if language.lower() in ['chinese', 'zh', 'ä¸­æ–‡']:
            prompt = f"""
è«‹æ ¹æ“šä»¥ä¸‹ä¸‰ä»½ç¾åœ‹è‚¡å¸‚å¸‚å ´æƒ…ç·’è³‡æ–™ï¼Œæ’°å¯«ä¸€ä»½æ·±å…¥çš„å¸‚å ´æƒ…ç·’åˆ†æå ±å‘Šã€‚èªæ°£æ‡‰å°ˆæ¥­ã€å®¢è§€ï¼Œå…§å®¹æ‡‰å¹«åŠ©ä¸€èˆ¬æŠ•è³‡è€…ç†è§£ç›®å‰å¸‚å ´æ°£æ°›ï¼Œä¸¦å¾ä¸­æŒ–æ˜æ½›åœ¨çš„æŠ•è³‡æ©Ÿæœƒèˆ‡éœ€é—œæ³¨çš„ä¸»é¡Œã€‚

reddit:è¿‘30æ—¥é‡å°ç¾åœ‹è‚¡å¸‚æƒ…ç·’ {df}

ğŸ“Œ 1. æ•´é«”å¸‚å ´æƒ…ç·’æ‘˜è¦ï¼š
{sentiment_summary}

ğŸ“Š 2. æœ¬é€±å‰äº”å¤§ç†±é–€ç”¢æ¥­ï¼š
{top_sector_summary}

ğŸ“ˆ 3. æœ¬é€±å‰åç†±é–€è‚¡ç¥¨ï¼š
{symbol_summary}

è«‹æ’°å¯«ç´„ 400â€“600 å­—çš„åˆ†æå ±å‘Šï¼Œçµæ§‹åŒ…å«ä»¥ä¸‹é‡é»ï¼š

1. **å¸‚å ´æƒ…ç·’è®ŠåŒ–è¶¨å‹¢**ï¼šèªªæ˜æŠ•è³‡äººæƒ…ç·’æ˜¯å¦åå‘æ¨‚è§€ã€ä¿å®ˆæˆ–çŒ¶è±«ï¼Œä¸¦è§£é‡‹å¯èƒ½çš„é©…å‹•å› ç´ ã€‚

2. **ç”¢æ¥­èˆ‡è‚¡ç¥¨ç†±åº¦è§£è®€**ï¼šåˆ†æå“ªäº›ç”¢æ¥­èˆ‡å€‹è‚¡å—åˆ°ç‰¹åˆ¥é—œæ³¨ï¼Œæ˜¯å¦æœ‰ç‚’ä½œæˆ–éç†±è·¡è±¡ï¼Œä»¥åŠé€™äº›ç¾è±¡æ˜¯å¦å¯èƒ½æŒçºŒã€‚

3. **è³‡é‡‘å¯èƒ½æµå‘èˆ‡é¢¨éšªæç¤º**ï¼šæ ¹æ“šç†±åº¦è³‡æ–™æ¨æ¸¬æ½›åœ¨çš„å¸‚å ´æµå‘ï¼Œä¸¦æé†’ç›¸é—œé¢¨éšªï¼Œä¾‹å¦‚çŸ­æœŸæŠ•æ©Ÿã€æ”¿ç­–è®Šæ•¸æˆ–ä¼°å€¼æ³¡æ²«ã€‚

4. **é—œéµè©±é¡Œæ¨è–¦**ï¼šæ ¹æ“šåˆ†æå…§å®¹èˆ‡å‰åç†±é–€è©±é¡Œï¼Œåˆ—å‡ºè®€è€…å¯é€²ä¸€æ­¥æŸ¥è©¢çš„å…·é«”é—œéµå­—æˆ–ä¸»é¡Œï¼ˆå¦‚ï¼šã€ŒAIæ™¶ç‰‡ã€ã€ã€Œå¯å†ç”Ÿèƒ½æºè£œè²¼ã€ã€ã€Œè¯æº–æœƒæœƒè­°ç´€è¦ã€ã€ã€ŒåŠå°é«”åº«å­˜ã€ã€ã€Œå¤§å‹ç§‘æŠ€è‚¡å›è³¼ã€ç­‰ï¼‰ã€‚

5. **æŠ•è³‡å»ºè­°**ï¼šç”¨æ·ºç™½ã€å‹™å¯¦çš„èªè¨€æå‡ºæ‡‰å°ç•¶å‰å¸‚å ´æƒ…ç·’çš„ç­–ç•¥å»ºè­°ï¼Œä¾‹å¦‚ï¼šåˆ†æ•£é…ç½®ã€çŸ­ç·šè§€æœ›æˆ–èšç„¦åŸºæœ¬é¢ç­‰ã€‚

è«‹è®“å ±å‘Šæ¢ç†æ¸…æ™°ï¼Œæ®µè½åˆ†æ˜ï¼Œçµå°¾å¯åŠ å…¥ç°¡çŸ­ç¸½çµæˆ–è§€å¯Ÿæ–¹å‘ã€‚
"""
        else:
            prompt = f"""
You are a professional market analyst. Based on the following U.S. stock market sentiment data, generate a structured and insightful sentiment analysis report. The tone should be professional yet approachable, helping non-expert investors understand how public mood and discussions are shaping the market.

Reddit sentiment data (past 30 days):
{df}

ğŸ“Œ 1. Overall Sentiment Summary:
{sentiment_summary}

ğŸ“Š 2. Top 5 Sectors This Week:
{top_sector_summary}

ğŸ“ˆ 3. Top 10 Symbols This Week:
{symbol_summary}

Please organize your analysis into 4â€“5 clear paragraphs (approx. 400â€“600 words), covering the following:

1. **Sentiment Trend Overview**: Identify whether current market sentiment appears optimistic, cautious, or divided. Highlight any major shifts or acceleration in discussions.

2. **Sector & Symbol Focus**: Discuss any sectors or companies receiving disproportionate attention. Are there signs of overhype, speculation, or organic momentum?

3. **Emerging Investment Themes**: From the data, extract recurring themes or market narratives (e.g., AI, clean energy, monetary policy). Describe how these are influencing investor perception.

4. **Key Topics to Research**: Based on the top trending topics, suggest a list of specific themes or keywords that investors may want to research further (e.g., "Nvidia AI chips", "renewable subsidies", "Fed policy", "semiconductor inventory").

5. **Practical Recommendations**: Offer simple, actionable guidance on how investors might position themselves based on the current sentiment climateâ€”whether to stay cautious, diversify, or monitor specific trends.

Conclude the report with a concise summary and any forward-looking considerations.
"""
        # å‘¼å« GPT API
        res = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "You are a financial analyst specializing in interpreting market sentiment data."
                },
                {"role": "user", "content": prompt}
            ]
        )

        report = res.choices[0].message.content
        print(report) 
        return report, report

    except Exception as e:
        return f"Error generating sentiment report: {e}"

# ----------send email-----------

def update_report_and_return(economic_summary,market_sentiment_summary,stock_recommender_summary,language):
    return generate_overall_report(economic_summary,market_sentiment_summary,stock_recommender_summary,language)

def send_latest_report(email):
    return send_email_report(email, "Your Personalized Investment Report", last_generated_report)

# ---------- LangChain Agent ----------

news_tool = Tool(name="SearchNews", func=lambda q: search_news_for_keywords([q]), description="search news")
wiki_tool = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(lang="en"))

agent = initialize_agent(
    [news_tool, 
    Tool.from_function(wiki_tool, name="Wikipedia", description="search wikipedia")],
    llm=llm,
    agent="conversational-react-description",
    verbose=True,
    handle_parsing_errors=True  
)

def convert_to_langchain_chat_history(gradio_history):
    
    chat_history = []
    for msg in gradio_history:
        if isinstance(msg, dict):
            role = msg.get("role")
            content = msg.get("content")
            if role == "user":
                chat_history.append(("user", content))
            elif role == "assistant":
                chat_history.append(("assistant", content))
    return chat_history

def continue_chat_with_agent(history, user_input):
    try:
        chat_history_lc = convert_to_langchain_chat_history(history)

        agent_reply = agent.invoke({
            "input": user_input,
            "chat_history": chat_history_lc
        })

        if hasattr(agent_reply, "content"):
            agent_reply = agent_reply.content
        elif isinstance(agent_reply, dict) and "output" in agent_reply:
            agent_reply = agent_reply["output"]
        else:
            agent_reply = str(agent_reply)

    except Exception as e:
        agent_reply = f"Agent éŒ¯èª¤ï¼š{e}"

    history = history + [
        {"role": "user", "content": str(user_input)},
        {"role": "assistant", "content": str(agent_reply)}
    ]
    return history, history, ""

# ---------- dropdown 
def get_index_list():
                try:
                    res = requests.get("http://fastapi:8000/economic_index/list")
                    return res.json() if res.status_code == 200 else []
                except Exception as e:
                    print("Error loading index list:", e)
                    return []
def get_market_list():
    try:
        res = requests.get(f"{API_BASE}/market_price/list")
        return res.json() if res.status_code == 200 else []
    except Exception as e:
        print("Market list error:", e)
        return []
# ---------- Gradio UI ----------
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ“Š Adrian's US Stock Weekly Report")
    user_state = gr.State() 

    with gr.Tabs():
        # --- Tab 1: Questionnaire ---
        with gr.Tab(" Main page (é¦–é ) "):
            
            with gr.Row():    
                with gr.Column(scale=1):
                    image_output = gr.Image(show_image("Intro_page.png"),width=900,height=850,type="pil")
                    
                with gr.Column(scale=1):
                    gr.Markdown("""
            ## ğŸ’¸ Welcome to Your AI U.S. Stock Investment Assistant

            I am Money, your smart investment assistant.I'm here to help you build a smarter U.S. stock strategy.  
            By understanding your background, experience, and preferences, we can tailor investment recommendations just for you.  

            ğŸ‘‰ Take a moment to complete the short survey on the right to get started.
            """)
                    age = gr.Dropdown(["18-25", "26-35", "36-45", "46-60", "60+"], label="Your Age Group")
                    experience = gr.Radio(["Beginner", "Intermediate", "Advanced"],value="Intermediate", label="Investment Experience")
                    interest = gr.CheckboxGroup(
                        ["Tech Stocks", "ETF", "High Dividend", "US Bonds", "Forex", "Crypto"],value="High Dividend",
                        label="Investment Preferences"
                    )
                    sources = gr.Textbox(
                        label="Stock or Keywords You Follow",
                        placeholder="e.g., Nvidia, Tesla......"
                    )
                    risk = gr.Radio(["Conservative", "Moderate", "Aggressive"],value="Moderate", label="Risk Tolerance")
                    language = gr.Radio(["English", "chinese"],  value="English", label = "language")
                    email = gr.Textbox(label = "Your Email (for report delivery)", placeholder="example@email.com")
                    submit_btn = gr.Button("Submit")
                    output = gr.Textbox(label="Submission Status", interactive=False)

                    submit_btn.click(
                        fn = save_to_db,
                        inputs=[age, experience, interest, sources, risk, language, email],
                        outputs=[output, user_state]
                        )

        with gr.Tab(" Economic & Market Trendsï¼ˆç¶“æ¿Ÿèˆ‡å¸‚å ´è¶¨å‹¢ï¼‰"):
            with gr.Row():
                 with gr.Column(scale=1):
                    gr.Markdown("## Economic Indicator ç¶“æ¿ŸæŒ‡æ•¸")
                    
                    print("Index list:", get_index_list())  # check if this is empty or fails
                    print("Market list:", get_market_list())

                    with gr.Row():
                        index_dropdown = gr.Dropdown(label="Select Index",choices = get_index_list(),value=None,scale=2)
                        days_input = gr.Number(label="Days Range",value=180,precision=0,scale=1)
    
                    chart_output = gr.Plot()

                    def update_single_chart(index_name, days):
                        if not index_name:
                            return go.Figure().update_layout(title="Please select an index.")
                        df, _ = fetch_economic_index_summary(index_name=index_name, days=int(days))
                        return plot_index_chart(df, title=f"{index_name} Trend")
                
                    index_dropdown.change(
                        fn=update_single_chart, 
                        inputs=[index_dropdown, days_input], 
                        outputs = chart_output,
                        queue=True,
                        )
                    days_input.change(
                        fn = update_single_chart, 
                        inputs = [index_dropdown, days_input],
                        outputs = chart_output,
                        queue=True,
                        )

                 with gr.Column(scale=1):
                    gr.Markdown("## Market Price å¸‚å ´èµ°å‹¢")

                    market_dropdown = gr.Dropdown(label="Select Market", choices=get_market_list(), value=None)
                    market_chart_output = gr.Plot()
                    
                    def update_market_chart(market):
                        if not market:
                            return go.Figure().update_layout(title="Please select a market.")
                        df, _ = fetch_market_price_summary(market)
                        return plot_price_chart(df, title=f"{market} Price Trend")


                    market_dropdown.change(fn=plot_price_chart, inputs=[market_dropdown], outputs=[market_chart_output])
            
            gr.Markdown("###  AI Agent è¶¨å‹¢åˆ†æå°å¹«æ‰‹ ")

            ai_generated_report = gr.TextArea(label="ğŸ“„ AI Analysis Report", lines=25)
            economic_report_state = gr.State()
            generate_btn = gr.Button(" Generate Trend Report")

            
            generate_btn.click(
            fn=get_economic_report,
            inputs=[language],
            outputs=[ai_generated_report,economic_report_state]
        )
            
        with gr.Tab(" Market Sentiments (å¸‚å ´æƒ…ç·’) "):
            with gr.Row():
                with gr.Column(scale=1): 
                    gr.Markdown("###  Daily Sentiment about Us Stock ç¾è‚¡å¸‚å ´æƒ…ç·’(30æ—¥)") 
                    sentiment_chart = gr.Plot(label="Sentiment Line Chart")
                    chart_btn = gr.Button(" Refresh Trend")
                
                with gr.Column(scale=1):
                    gr.Markdown("###  Weekly Reddit Sentiment about Us Stock ç¾è‚¡å¸‚å ´æƒ…ç·’(æ¯é€±)")  
                    pie1 = gr.Plot(label="This Week Sentiment")
                    pie2 = gr.Plot(label="Last Week Sentiment")
                    pie_btn = gr.Button("Update Weekly Comparison")

            def update_sentiment_pie():
                df, err = fetch_sentiment_data()
                if err:
                    return go.Figure().update_layout(title=err), go.Figure(), err
                fig1, fig2 = plot_sentiment_pie(df)
                return fig1, fig2

            gr.Markdown("###  Top 10 Topic about Us Stock ç¾è‚¡ç†±é–€è¨è«–è©±é¡Œ") 

            sentiment_table = gr.Dataframe(label=" Sentiment Topic Summary",wrap=True)
            last_time_text = gr.Markdown()
            table_btn = gr.Button("ğŸ”„ Refresh")

            def get_top_10_topic():
                df,_ = get_sentiment_table()
                return df
                
            table_btn.click(
                fn = get_sentiment_table,
                outputs = sentiment_table
            )

            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown(" ### Pooular Sector and Ticker (ç†±é–€ç”¢æ¥­) ")

                    chart_output = gr.Plot(label="Weekly Top 5 Sector")
                    last_time_text = gr.Markdown()
                    refresh_btn1 = gr.Button("ğŸ”„ Refresh")
                
                with gr.Column(scale=1):
                    gr.Markdown(" ### Top 10 Stock Discussions (ç†±é–€æ¨™åœ°) ")    
                    symbol_table = gr.Dataframe(wrap = True,interactive=False)

                    refresh_btn2 = gr.Button("ğŸ”„ Refresh")

            def fetch_top10_symbols_df():
                df,_ = fetch_top10_symbols_this_week()
                return df
                
            refresh_btn2.click(
                fn= fetch_top10_symbols_df,
                outputs=symbol_table
                )


            gr.Markdown("###  AI Agent å¸‚å ´æƒ…ç·’åˆ†æå°å¹«æ‰‹ ")

            ai_sentiment_report = gr.TextArea(label="ğŸ“„ AI Analysis Report", lines=25)
            sentiment_report_state = gr.State() 
            sentiment_report_generate_btn = gr.Button(" Generate Trend Report")

            
            sentiment_report_generate_btn.click(
            fn = get_market_sentiment_report,
            inputs = [language],
            outputs = [ai_sentiment_report,sentiment_report_state]
            )

            refresh_btn1.click(
                fn= plot_sector_chart,
                outputs= chart_output
            )
           
            
            chart_btn.click(
                plot_sentiment_line_chart,
                outputs = sentiment_chart
                )


            pie_btn.click(
                fn=update_sentiment_pie, 
                outputs=[pie1, pie2]
                )

            demo.load(fn=plot_sentiment_line_chart, outputs=sentiment_chart)
            demo.load(fn=get_sentiment_table, outputs=[sentiment_table,last_time_text])
            demo.load(fn=plot_sector_chart, outputs=chart_output)
            demo.load(fn=fetch_top10_symbols_df, outputs=symbol_table)
            demo.load(fn=update_sentiment_pie, outputs=[pie1, pie2])


        max_snapshot_date = fetch_max_date()
        industries = fetch_industries()
        with gr.Tab(" SP500 ç¾è‚¡ç³¾å¯ŸéšŠ"):
            
            
            gr.Markdown("### è‚¡ç¥¨æ¨è–¦ç³»çµ±")

            with gr.Row():
                with gr.Column(scale=2):
                    stock_input = gr.Textbox(
                        label="è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼ˆä¾‹å¦‚ï¼šGOOG, AAPL, MSFTï¼‰", lines=2, placeholder="GOOG, AAPL, MSFT"
                    )
                    submit_button = gr.Button("æŸ¥è©¢æ¨è–¦")
                with gr.Column(scale=3):
                    error_output = gr.Textbox(label="éŒ¯èª¤è¨Šæ¯", visible=False)
                    recommend_output = gr.Textbox(label="æ¨è–¦è‚¡ç¥¨", lines=6)

            submit_button.click(
                fn=g4_recommend_multi,
                inputs=[stock_input,email],
                outputs=[error_output, recommend_output]
            )
            

            gr.Markdown("### ğŸ¤– AI è‚¡ç¥¨æ¨è–¦åˆ†æ")

            with gr.Row():
                holdings_input = gr.Textbox(label="ç›®å‰æŒæœ‰è‚¡ç¥¨ (é€—è™Ÿåˆ†éš”)", placeholder="AAPL, TSLA")
                recommended_input = gr.Textbox(label="æ¨è–¦è‚¡ç¥¨ (é€—è™Ÿåˆ†éš”)", placeholder="MSFT, GOOG")

            ai_output = gr.Textbox(label="AI åˆ†æå»ºè­°", lines=20)
            stock_recommendation_state = gr.State()
            analyze_button = gr.Button("åˆ†ææ¨è–¦")

            def call_ai_analysis(holdings, recommended, style, risk):
                payload = {
                    "holdings": [s.strip() for s in holdings.split(",") if s.strip()],
                    "recommended": [s.strip() for s in recommended.split(",") if s.strip()],
                    "style_preference":style,
                    "risk_tolerance": risk
                }
                try:
                    res = requests.post("http://fastapi:8000/ai/stock_recommender", json=payload)
                    res.raise_for_status()
                    result = res.json()["analysis"]
                    return "\n\n".join(result.split("\n\n")) ,result
                except Exception as e:
                    return f"âŒ Error: {str(e)}"

            analyze_button.click(
                fn=call_ai_analysis,
                inputs=[holdings_input, recommended_input, interest, risk],
                outputs=[ai_output,stock_recommendation_state]
            )
            
            gr.Markdown("### ğŸ“Š S&P 500 Stock Data")

            with gr.Row():
                symbol_input = gr.Textbox(label="Symbol")
                sector_input = gr.Dropdown(label="sector", choices = industries,value="")
                start_date = gr.Textbox(label="Start Date (YYYY-MM-DD)", value=str(max_snapshot_date))
                end_date = gr.Textbox(label="End Date (YYYY-MM-DD)", value=str(max_snapshot_date)) 

            output = gr.Dataframe(label="æŸ¥è©¢çµæœ", interactive=False)
            search_btn = gr.Button("æŸ¥è©¢")

            search_btn.click(
                query_stock_data,
                inputs=[symbol_input, sector_input, start_date, end_date],
                outputs=output
            )

        with gr.Tab("ğŸ“„ View Report"):
                
            output_text = gr.TextArea(label="ğŸ“„ Report Content", lines=20) 
            send_status = gr.Textbox(label="ğŸ“¬ Email Status", interactive=False)

            with gr.Row():
                submit_btn = gr.Button("ğŸ“ Generate Report")
                send_btn = gr.Button("ğŸ“¤ Send Report via Email")

            with gr.Row():  
                with gr.Column(scale=2):
                    chatbox = gr.Chatbot(type="messages")
                    with gr.Row():
                        msg_input = gr.Textbox(placeholder="è¼¸å…¥ä½ çš„å•é¡Œ", label="å•é¡Œ")
                        state = gr.State([]
                                         )
                with gr.Column(scale=1):
                    image_output = gr.Image(
                        value=show_image("fin_page.png"), 
                        width= 800,
                        height= 500,
                        type="pil"
                    )

                    
            # Function bindings
            
            submit_btn.click(
                fn = update_report_and_return,
                inputs=[economic_report_state,sentiment_report_state,stock_recommendation_state,language],
                outputs=output_text
            )

            send_btn.click(
                fn=send_latest_report,
                inputs=email,
                outputs=send_status
            )

            msg_input.submit(
                fn=continue_chat_with_agent,
                inputs=[state, msg_input],  
                outputs=[chatbox, state, msg_input]
            )

if __name__ == '__main__':
    print("Gradio version in use:", gr.__version__)
    demo.launch(server_name="0.0.0.0", server_port=7860)
    

# nodes.py
from typing import TypedDict, Literal
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from .prompt import build_prompt
from services.translation_service import translate_text

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)

class AgentState(TypedDict):
    language: str
    economic_summary: str
    sentiment_summary: str
    stock_summary: str
    user_profile: dict 
    report: str

# LLM ç¯€é»ï¼šç”¢ç”Ÿå®Œæ•´å ±å‘Š
def generate_report(state: AgentState) -> AgentState:
    prompt = build_prompt(
        lang=state["language"],
        user=state["user_profile"],
        econ=state["economic_summary"],
        sentiment=state["sentiment_summary"],
        stock=state["stock_summary"]
    )

    messages = [
        SystemMessage(content="You are a senior investment strategist who synthesizes multi-source information."),
        HumanMessage(content=prompt)
    ]
    result = llm.invoke(messages)
    return {**state, "report": result.content}

# æ¢ä»¶ç¯€é»ï¼šåˆ¤æ–·æ˜¯å¦ç¿»è­¯
def should_translate(state: AgentState) -> Literal["translate", "skip"]:
    return "translate" if state["language"].lower() in ["chinese", "zh", "\u4e2d\u6587"] else "skip"

def translate_service(state: AgentState) -> AgentState:
    target_lang = state["language"]
    original_report = state["report"]

    print("ğŸˆ¶ ç¿»è­¯å•Ÿå‹•ï¼åŸå§‹å ±å‘Šå‰ 50 å­—ï¼š", state["report"][:50])

    # å‘¼å«ç¿»è­¯æœå‹™
    translated_report = translate_text(original_report, target_lang)
    print("ğŸˆ¯ ç¿»è­¯å®Œæˆï¼å‰ 50 å­—ï¼š", translated_report[:50])

    # å›å‚³æ–°çš„ stateï¼Œè¦†è“‹åŸæœ¬ report ç‚ºç¿»è­¯å¾Œç‰ˆæœ¬
    return {**state, "report": translated_report}
